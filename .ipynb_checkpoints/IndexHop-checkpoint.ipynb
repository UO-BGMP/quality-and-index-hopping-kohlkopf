{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Quality-and-Index-Hopping\" data-toc-modified-id=\"Quality-and-Index-Hopping-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Quality and Index Hopping</a></div><div class=\"lev2 toc-item\"><a href=\"#Quality-Distributions\" data-toc-modified-id=\"Quality-Distributions-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Quality Distributions</a></div><div class=\"lev3 toc-item\"><a href=\"#Plotting-script\" data-toc-modified-id=\"Plotting-script-111\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Plotting script</a></div><div class=\"lev2 toc-item\"><a href=\"#Index-Hopping\" data-toc-modified-id=\"Index-Hopping-12\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Index Hopping</a></div><div class=\"lev3 toc-item\"><a href=\"#Index-hopping-script\" data-toc-modified-id=\"Index-hopping-script-121\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Index hopping script</a></div><div class=\"lev3 toc-item\"><a href=\"#Results\" data-toc-modified-id=\"Results-122\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Results</a></div><div class=\"lev2 toc-item\"><a href=\"#Questions\" data-toc-modified-id=\"Questions-13\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Questions</a></div><div class=\"lev3 toc-item\"><a href=\"#Lines-in-files\" data-toc-modified-id=\"Lines-in-files-131\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Lines in files</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quality and Index Hopping\n",
    "**Kohl Kinning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate per base call distribution of quality scores for read1, read2, index1, and index2. Generate a per nucleotide distribution. Next, average the Quality scores for each read (for each of the four files) and plot frequency of the Quality Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import argparse\n",
    "\n",
    "\n",
    "def get_arguments():\n",
    "    parser = argparse.ArgumentParser(prog='qscore_plot', description= 'Outputs a distribution of quality scores as a function of the base position of sequencing reads.')\n",
    "\n",
    "    parser.add_argument('-f', '--infile', help='fastq filepath', required=True, type=argparse.FileType('rt', encoding='UTF-8 '))\n",
    "\n",
    "    return parser.parse_args()\n",
    "\n",
    "def convert_phred(letter):\n",
    "    score = ord(letter) - 33    # phred+33\n",
    "    return score\n",
    "\n",
    "\n",
    "args = get_arguments()\n",
    "file = args.infile.name\n",
    "\n",
    "all_scores = np.zeros(101)\n",
    "mean_read_scores = Counter()\n",
    "\n",
    "\n",
    "with open(file, 'r') as fh:\n",
    "    count = 0\n",
    "    NR = 1\n",
    "    for line in fh:\n",
    "        line = str(line).strip('\\n')\n",
    "        count = 2\n",
    "        if NR % 4 == 0:  # quality line\n",
    "            ntd_pos = 0\n",
    "            read_score = 0\n",
    "            for ntd in line:\n",
    "                all_scores[ntd_pos] = ((int(convert_phred(ntd)) + all_scores[ntd_pos]) / (count))\n",
    "\n",
    "                read_score += int(convert_phred(ntd))\n",
    "                read_avg = int(read_score // len(line))  # floor div\n",
    "                ntd_pos += 1\n",
    "            count += 1\n",
    "\n",
    "            mean_read_scores[read_avg] += 1\n",
    "        NR += 1 \n",
    "\n",
    "# quality score distribution of reads\n",
    "xdata = np.arange(0, len(all_scores[all_scores > 0]), 1)\n",
    "plt.figure()\n",
    "plt.bar(xdata, all_scores[all_scores > 0], width = 0.5)\n",
    "\n",
    "print(all_scores[all_scores > 0])\n",
    "\n",
    "plt.title(str(file) + '\\n' + 'Mean Quality Score by Base Position')\n",
    "plt.xlabel('Base Position')\n",
    "plt.ylabel('Mean Quality Score')\n",
    "plt.savefig(file + '_distribReads.png')\n",
    "\n",
    "\n",
    "\n",
    "# quality score distribution across all reads\n",
    "x = []\n",
    "y = []\n",
    "for key in mean_read_scores:\n",
    "    x.append(key)\n",
    "    y.append(mean_read_scores[key])\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(x, y, width = 0.5)\n",
    "plt.title(str(file) + '\\n' + 'Frequency of Average Quality Score Across All Reads')\n",
    "plt.xlabel('Avg score per read')\n",
    "plt.ylabel('Frequency')\n",
    "plt.savefig(file + '_distribAll.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index Hopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a program to de-multiplex the samples and document index swapping and number of reads retained per sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index hopping script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3.6\n",
    "\n",
    "import argparse\n",
    "import itertools\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def complement(seq):\n",
    "    complement = {'C': 'G', 'T': 'A', 'A': 'T',  'G': 'C', 'N': 'N'}\n",
    "    ntds = list(seq)\n",
    "    ntds = [complement[ntd] for ntd in ntds]\n",
    "    return ''.join(ntds)\n",
    "\n",
    "\n",
    "def reverse_complement(s):\n",
    "        return complement(s[::-1])\n",
    "\n",
    "\n",
    "def get_arguments():\n",
    "    parser = argparse.ArgumentParser(prog='index_hopping', description= 'Demultiplexing of paired end sequences by index paring')\n",
    "    parser.add_argument('-1', '--R1', help='R1 file path', required=True, type=argparse.FileType('rt', encoding='UTF-8 '))\n",
    "    parser.add_argument('-2', '--R2', help='R2 file path', required=True, type=argparse.FileType('rt', encoding='UTF-8 '))\n",
    "    parser.add_argument('-3', '--R3', help='R3 file path', required=True, type=argparse.FileType('rt', encoding='UTF-8 '))\n",
    "    parser.add_argument('-4', '--R4', help='R4 file path', required=True, type=argparse.FileType('rt', encoding='UTF-8 '))\n",
    "    parser.add_argument('-c', '--minScore', help='Quality score cutoff', required=True, type=int)\n",
    "    parser.add_argument('-i', '--ind', help='Index file path', required=True, type=argparse.FileType('rt', encoding='UTF-8 '))\n",
    "\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "args = get_arguments()\n",
    "\n",
    "min_score = args.qcutoff\n",
    "\n",
    "R1 = args.R1.name\n",
    "R2 = args.R2.name\n",
    "R3 = args.R3.name\n",
    "R4 = args.R4.name\n",
    "index = args.ind.name\n",
    "\n",
    "\n",
    "index_dict = {}\n",
    "\n",
    "with open(index, 'r') as ind:\n",
    "    for line in ind:\n",
    "        line = line.strip('\\n').split('\\t')\n",
    "        index_dict[line[3]] = line[4]\n",
    "\n",
    "\n",
    "all_indices = []\n",
    "\n",
    "for key in index_dict:\n",
    "    all_indices.append(index_dict[key])\n",
    "\n",
    "\n",
    "all_pairs_list = list(itertools.combinations_with_replacement(all_indices, 2))\n",
    "\n",
    "all_pairs_dict = {}\n",
    "\n",
    "for pair in all_pairs_list:\n",
    "    all_pairs_dict[pair] = 0\n",
    "\n",
    "undetermined_dict = Counter()\n",
    "\n",
    "with open(R1 ,'r') as r1, open(R2, 'r') as r2, open(R3, 'r') as r3, open(R4, 'r') as r4:\n",
    "    NL = 0\n",
    "    \n",
    "    for line in zip(r1, r2, r3, r4):\n",
    "        line = [l.strip() for l in line]\n",
    "        if NL % 4 == 0:\n",
    "            head = line\n",
    "        if NL % 4 == 1:\n",
    "            seq = line\n",
    "        if NL % 4 == 2:\n",
    "            plus = line\n",
    "        if NL % 4 == 3:\n",
    "            qline = line\n",
    "            for j in qline[1:2]:\n",
    "                qlist = []\n",
    "                qtotal = 0\n",
    "                for qual in j:\n",
    "                    qtotal += ord(qual) - 33\n",
    "                    qavg = qtotal/len(j)\n",
    "                    if qavg >= min_score:\n",
    "                        qlist.append(qual)\n",
    "                        pair = seq[1], reverse_complement(seq[2])\n",
    "                        if pair in all_pairs_dict:\n",
    "                            all_pairs_dict[pair] += 1\n",
    "                        else:\n",
    "                            undetermined_dict[pair] += 1\n",
    "        NL += 1\n",
    "\n",
    "\n",
    "match = open('matched.tsv', 'w')\n",
    "match.write('Matched Index Pair\\tCounts\\n')\n",
    "\n",
    "swap = open('swapped.tsv', 'w')\n",
    "swap.write('Swapped Index Pair\\tCounts\\n')\n",
    "\n",
    "und = open('undetermined.tsv', 'w')\n",
    "und.write('Undetermined Index Pair\\tCounts\\n')\n",
    "\n",
    "\n",
    "swapped = 0\n",
    "for pair in all_pairs_dict:\n",
    "    if pair[0] == pair[1]:\n",
    "        match.write(str(pair[0]) + '_' + str(pair[1]) + '\\t' + str(all_pairs_dict[pair]) + '\\n')\n",
    "    else:\n",
    "        swapped += 1\n",
    "        swap.write(str(pair[0]) + '_' + str(pair[1]) + '\\t' + str(all_pairs_dict[pair]) + '\\n')\n",
    "\n",
    "for pair in undetermined_dict:\n",
    "    und.write((str(pair[0]) + '_' + str(pair[1]) + '\\t' + str(undetermined_dict[pair]) + '\\n'))\n",
    "\n",
    "\n",
    "matched = 0\n",
    "for pair in all_pairs_dict:\n",
    "    matched += all_pairs_dict[pair]\n",
    "\n",
    "undetermined = 0\n",
    "for com in undetermined_dict:\n",
    "    undetermined += undetermined_dict[com]\n",
    "\n",
    "stats = open('metrics.tsv', 'w')\n",
    "stats.write('Filtered' + '\\t' + 'Matched' + '\\t' + 'Swapped' + '\\t' + 'Undetermined' + '\\n')\n",
    "stats.write(str(matched+swapped+undetermined) + '\\t' + str(matched) + '\\t' + str(swapped) + '\\t' + str(undetermined)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Matched Index Pair', 'Counts'],\n",
       " ['index sequence_index sequence', '0'],\n",
       " ['GTAGCGTA_GTAGCGTA', '15170760'],\n",
       " ['CGATCGAT_CGATCGAT', '10424338'],\n",
       " ['GATCAAGG_GATCAAGG', '12168683'],\n",
       " ['AACAGCGA_AACAGCGA', '16933442'],\n",
       " ['TAGCCATG_TAGCCATG', '19843352'],\n",
       " ['CGGTAATC_CGGTAATC', '9246665'],\n",
       " ['CTCTGGAT_CTCTGGAT', '65953935'],\n",
       " ['TACCGGAT_TACCGGAT', '146346803']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "matched_list = []\n",
    "\n",
    "with open('matched.tsv','r') as matched:\n",
    "    matched = csv.reader(matched, delimiter='\\t')\n",
    "    for row in matched:\n",
    "        matched_list.append(row)\n",
    "        \n",
    "matched_list[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Swapped indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Swapped Index Pair', 'Counts'],\n",
       " ['TAGCGTA_CGATCGAT', '307'],\n",
       " ['GTAGCGTA_GATCAAGG', '385'],\n",
       " ['GTAGCGTA_AACAGCGA', '513'],\n",
       " ['GTAGCGTA_TAGCCATG', '458'],\n",
       " ['GTAGCGTA_CGGTAATC', '227'],\n",
       " ['GTAGCGTA_CTCTGGAT', '1344'],\n",
       " ['GTAGCGTA_TACCGGAT', '2869'],\n",
       " ['GTAGCGTA_CTAGCTCA', '1293'],\n",
       " ['GTAGCGTA_CACTTCAC', '173']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "swapped_list = []\n",
    "\n",
    "with open('swapped.tsv','r') as swapped:\n",
    "    swapped = csv.reader(swapped, delimiter='\\t')\n",
    "    for row in swapped:\n",
    "        swapped_list.append(row)\n",
    "        \n",
    "swapped_list[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undetermined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Undetermined Index Pair', 'Counts'],\n",
       " ['NCTTCGAC_TCTTCGAN', '339360'],\n",
       " ['NACAGCGA_AACAGCGN', '71775'],\n",
       " ['NTCCTAAG_GTCCTAAN', '69054'],\n",
       " ['NATGGCAC_TATGGCAN', '88482'],\n",
       " ['NACCGGAT_TACCGGAN', '617101'],\n",
       " ['NTCTGGAT_CTCTGGAN', '276960'],\n",
       " ['NCGAGAGT_TCGAGAGN', '85296'],\n",
       " ['NGGATAGC_AGGATAGN', '69022'],\n",
       " ['NTCATGCG_ATCATGCN', '78633']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "und_list = []\n",
    "\n",
    "with open('undetermined.tsv','r') as und:\n",
    "    und = csv.reader(und, delimiter='\\t')\n",
    "    for row in und:\n",
    "        und_list.append(row)\n",
    "        \n",
    "und_list[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***What is a good quality score cutoff for index reads and pairs to utilize for sample identification and downstream analysis, respectively?***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose a cutoff of 30. My plots showed the vast majority of the quality scores as being above this limit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***How many indexes have Undetermined (N) base calls? (Utilize your command line tool knowledge. Summit the command you used. CHALLENGE: use a one line command)***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ awk \"NR%4==2\" /projects/bgmp/2017_sequencing/1294_S1_L008_R2_001.fastq | grep \"N\" | wc -l\n",
    "$ 3976613\n",
    "\n",
    "$ awk \"NR%4==2\" /projects/bgmp/2017_sequencing/1294_S1_L008_R3_001.fastq | grep \"N\" | wc -l\n",
    "$ 3328051\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***What do the averaged Quality Scores across the reads tell you? Interpret your data specifically.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The averaged quality scores are (to me) surprisingly high. I've read in the literature that 20 is a common cutoff value. I believe we had a high quality sequencing run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***How many reads are retained for each expected index pair? What is the percentage?***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "232,228,144 reads remained average being filtered by the cutoff value. Of these, 226,715,602 had appropriately matched indexes. There were 363,246,735 in total. ~62.4% remain "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***How many reads are indicative of index swapping?***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "330,975 reads were indicative of index swapping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Create a distribution of swapped indexes. What does this histogram tell you/what is your interpretation of this data?***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See `/plots/swappedDist.pdf`\n",
    "\n",
    "Though the plot is impossible to label legibly with index pairs as labels, we can still make use of the histogram. The important thing that it shows us is that the distribution of swapped indexes is not normal. There are some indexes that are found to be swapped at a much higher frequency than others."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "157px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": "3",
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
